{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7OLq2gjQoIk"
      },
      "source": [
        "# Big Data Analytics 2024 Project 1\n",
        "\n",
        "Name: Mohammed Abuzer Khanzade\n",
        "\n",
        "Course: MSc Data Science\n",
        "\n",
        "Birkbeck University of London\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kn_fObeaSqqu"
      },
      "source": [
        "# CineSense\n",
        "# 1. **Introduction**\n",
        "CineSense is a unique startup that deals with video processing using the most advanced natural language processing and computer vision techniques to extract valuable insight from video content on social media. In this age of businesses being run with a data-driven approach for analyses and future decisions, knowing the sentiment and emotional response of the audience is very vital. CineSense wants to bridge this gap by providing insightful information extracted from users' video content on social media platforms like YouTube.\n",
        "\n",
        "This project involves developing a Python application using multiprocessing, threading, or asynchronous programming concepts to download and analyze YouTube videos.\n",
        "\n",
        "The tasks include:\n",
        "\n",
        "*   Downloading YouTube videos.\n",
        "*   Extracting audio from videos.\n",
        "*   Transcribing audio to text.\n",
        "*   Performing sentiment analysis.\n",
        "*   Translating text into Spanish.\n",
        "*   Extracting emotions from the text.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBIStKm1LgeU"
      },
      "source": [
        "# 2. Setup and Installation\n",
        " It is essential to install all the necessary libraries before implementing any functionality. This ensures that all dependencies are met, and the code can run smoothly. The following libraries are required for downloading videos, extracting audio, transcribing audio, analyzing sentiment, and extracting emotions:\n",
        "\n",
        "*   **pytube**: Used for downloading YouTube videos.\n",
        "*   **moviepy**: Used for video editing and audio extraction.\n",
        "*   **speechrecognition**: Used for transcribing audio to text.\n",
        "*   **textblob**: Used for text processing, sentiment analysis, and translation.\n",
        "*   **nrclex**: Used for extracting emotions from text.\n",
        "*  **spacy and nltk**: Libraries for natural language processing tasks.\n",
        "*   **nltk.download('punkt')**: Downloads the tokenizer required by NLTK.\n",
        "*   **textblob.download_corpora**: Downloads the necessary corpora for TextBlob.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kdzxEGp9Vclj"
      },
      "outputs": [],
      "source": [
        "!pip install pytube moviepy speechrecognition textblob nrclex spacy nltk\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "!python -m textblob.download_corpora\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djHD3Kvv_VE9"
      },
      "source": [
        "# 3. Creating Video URLs\n",
        "This code defines a list of YouTube video URLs and writes them to a text file named **'video_urls.txt'**. This file will be used as the source for downloading videos. The function verifies the content of the file by reading and printing it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZ7qp8haViM7"
      },
      "outputs": [],
      "source": [
        "# Creats video_urls.txt file\n",
        "def main_create_urls():\n",
        "    urls = [\n",
        "        \"https://youtu.be/9h2bKsJ7j_c?si=JmzURQROnXAJbrr5\",\n",
        "        \"https://youtu.be/hCXYxufbDag?si=qh1OCN6r9q7iTL4B\",\n",
        "        \"https://youtu.be/qYyxoor5Hk4?si=SoFp54_InaCAJ7hk\",\n",
        "        \"https://youtu.be/HisYsqqszq0?si=ClaUeFCAQnhxucc0\",\n",
        "        \"https://youtu.be/XR4Vy2a3MqY?si=dUuqAUs5yNPH2e9H\",\n",
        "        \"https://youtu.be/Y_9v5yPi2DE?si=cOmotMGkj20W8dwN\",\n",
        "        \"https://youtu.be/NbqKRCefJhU?si=NRByXUnCLNiOtEME\",\n",
        "        \"https://youtu.be/1aA1WGON49E?si=JGpFu6e9S-1f1Av2\",\n",
        "        \"https://youtu.be/XALBGkjkUPQ?si=plNbDeIQMGCQOlbF\",\n",
        "        \"https://youtu.be/nyhRNwTfydU?si=mkzLzO0Shw1lw6v3\",\n",
        "        \"https://youtu.be/n1fGPpuaDpw?si=hXAChznyw65EBeXf\",\n",
        "        \"https://youtu.be/5Intdml2m-0?si=X7Fzg7TvaQItoJoc\"\n",
        "    ]\n",
        "\n",
        "    with open('video_urls.txt', 'w') as f:\n",
        "        for url in urls:\n",
        "            f.write(f\"{url}\\n\")\n",
        "\n",
        "    # Verifyies the contents of the video_urls.txt file\n",
        "    with open('video_urls.txt', 'r') as file:\n",
        "        content = file.read()\n",
        "        print(content)\n",
        "\n",
        "main_create_urls()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVGMJOs_G65k"
      },
      "source": [
        "# 4. Reading URLs from File\n",
        "This code reads the URLs from the **'video_urls.txt'** file and prints them to verify the contents. The **'read_urls'** function reads the URLs from the specified file and returns them as a list of strings. The **'main_read_urls'** function reads the URLs using **'read_urls'** and prints them.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZOoPdRTtV6k4"
      },
      "outputs": [],
      "source": [
        "# Utility function to read URLs from file\n",
        "def read_urls(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        urls = file.readlines()\n",
        "    urls = [url.strip() for url in urls]\n",
        "    return urls\n",
        "\n",
        "def main_read_urls():\n",
        "    urls = read_urls('video_urls.txt')\n",
        "    print(urls)\n",
        "\n",
        "main_read_urls()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDZzWfILINX6"
      },
      "source": [
        "# 5. Downloading videos\n",
        "This section of the code handles downloading YouTube videos using both serial and parallel processing. It also logs the download activities. It defines a VideoDownloader class to manage video downloads. It includes methods for logging downloads, downloading videos, and handling downloads using both serial and parallel processing. The **'main_download'** function initiates the download process, first using serial and then parallel execution, and measures the time taken for each method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚ö† IMPORTANT NOTE ABOUT VIDEO DOWNLOAD CODE\n",
        "\n",
        "This YouTube download block **successfully ran in 2024 when the project was originally submitted**.\n",
        "\n",
        "All videos were downloaded using `pytube`, and the full processed outputs  \n",
        "(**Transcripts**, **Emotions.txt**, **Sentiment.txt**, `download_log.txt`)  \n",
        "are already included inside this project folder.\n",
        "\n",
        "---\n",
        "\n",
        "### ‚ùó WHY THE DOWNLOAD FAILS NOW (NOT A CODE BUG)\n",
        "\n",
        "As of 2025, YouTube has updated their platform and the original video URLs now return:\n",
        "\n",
        "- `HTTP Error 400: Bad Request`\n",
        "- `HTTP Error 403: Forbidden`\n",
        "- ‚ÄúThis video is private‚Äù\n",
        "- ‚ÄúVideo unavailable‚Äù\n",
        "\n",
        "This happens because the videos have become **private, region restricted, or blocked by YouTube**,  \n",
        "NOT because the code is incorrect.\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úî REVIEWER / USER NOTICE\n",
        "\n",
        "- This block **should NOT be executed again**\n",
        "- The dataset **already exists inside this project**\n",
        "- The purpose of this block is to document the original automated data collection step\n",
        "- The failure is due to external YouTube restrictions, **not code logic**\n",
        "\n",
        "---\n",
        "\n",
        "üìÅ OUTPUT FILES INCLUDED (NO NEED TO RE-DOWNLOAD)\n",
        "\n",
        "- /Transcripts/\n",
        "- /Translations/\n",
        "- Emotions.txt\n",
        "- Sentiment.txt\n",
        "- download_log.txt\n",
        "- video_urls.txt\n",
        "---\n",
        "\n",
        "### üü¢ SUMMARY\n",
        "\n",
        "| Item | Status |\n",
        "|------|--------|\n",
        "| Code correctness | ‚úî Valid and working in 2024 |\n",
        "| Runs now? | ‚ùå Blocked by YouTube |\n",
        "| Output present? | ‚úî Yes |\n",
        "| Should you run it again? | ‚ùå No |\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WMYL6KrBV8NE"
      },
      "outputs": [],
      "source": [
        "from pytube import YouTube\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from threading import Semaphore, Lock\n",
        "import time\n",
        "import os\n",
        "import logging\n",
        "from datetime import datetime\n",
        "\n",
        "# Setup logging to ensure the log file is saved in the correct directory\n",
        "log_file_path = '/content/download_log.txt'\n",
        "logging.basicConfig(filename=log_file_path, level=logging.INFO, format='%(asctime)s - %(message)s')\n",
        "log_lock = Lock()\n",
        "\n",
        "# Test writing to the log file\n",
        "with open(log_file_path, 'a') as log_file:\n",
        "    log_file.write('Log file created for debugging purposes.\\n')\n",
        "\n",
        "class VideoDownloader:\n",
        "    def __init__(self, max_threads=5):\n",
        "        self.semaphore = Semaphore(max_threads)\n",
        "        self.output_path = '/content/video_output'\n",
        "        if not os.path.exists(self.output_path):\n",
        "            os.makedirs(self.output_path)\n",
        "\n",
        "    def log_download(self, url):\n",
        "        with log_lock:\n",
        "            timestamp = datetime.now().strftime(\"%H:%M:%S, %d %B %Y\")\n",
        "            logging.info(f'\"Timestamp\": {timestamp}, \"URL\":\"{url}\", \"Download\":True')\n",
        "\n",
        "    def download_video(self, url):\n",
        "        try:\n",
        "            yt = YouTube(url)\n",
        "            stream = yt.streams.get_highest_resolution()\n",
        "            title = yt.title.replace(' ', '_').replace('/', '_')\n",
        "            video_folder = os.path.join(self.output_path, title)\n",
        "            if not os.path.exists(video_folder):\n",
        "                os.makedirs(video_folder)\n",
        "            stream.download(output_path=video_folder)\n",
        "            self.log_download(url)\n",
        "            print(f\"Downloaded: {yt.title}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to download {url}: {e}\")\n",
        "            with open(log_file_path, 'a') as log_file:\n",
        "                log_file.write(f'Failed to download {url}: {e}\\n')\n",
        "\n",
        "    def download_video_thread(self, url):\n",
        "        with self.semaphore:\n",
        "            self.download_video(url)\n",
        "\n",
        "    def serial_download(self, urls):\n",
        "        start_time = time.time()\n",
        "        for url in urls:\n",
        "            self.download_video(url)\n",
        "        end_time = time.time()\n",
        "        print(f\"Serial download time: {end_time - start_time} seconds\")\n",
        "\n",
        "    def parallel_download(self, urls):\n",
        "        start_time = time.time()\n",
        "        with ThreadPoolExecutor(max_workers=5) as executor:\n",
        "            executor.map(self.download_video_thread, urls)\n",
        "        end_time = time.time()\n",
        "        print(f\"Parallel download time: {end_time - start_time} seconds\")\n",
        "\n",
        "\n",
        "def main_download():\n",
        "    urls = read_urls('/content/video_urls.txt')\n",
        "    downloader = VideoDownloader()\n",
        "    print(\"Starting serial download...\")\n",
        "    downloader.serial_download(urls)\n",
        "    print(\"Starting parallel download...\")\n",
        "    downloader.parallel_download(urls)\n",
        "\n",
        "main_download()\n",
        "\n",
        "# Verify file creation\n",
        "!ls -l /content\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7GoZy6iIbeq"
      },
      "source": [
        "# Complexity Analysis\n",
        "\n",
        "**Time Complexity:**\n",
        "\n",
        "The time complexity is primarily dependent on network speed and response time of YouTube server. Parallel downloading significantly reduces total download time by leveraging multiple threads.\n",
        "\n",
        "*   **Serial Download:** O(n), where n is the number of videos.\n",
        "\n",
        "*   **Parallel Download:** O(n/k), where k is the number of threads, assuming ideal conditions without any significant overhead.\n",
        "\n",
        "**Space Complexity:**\n",
        "\n",
        "Both serial and parallel executions have a space complexity of O(1) for the individual download processes, as each video download does not depend on the size of the input but rather the space required to store the videos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPPmudysZ9JU"
      },
      "source": [
        "# 6. VideoAnalyzer Class: Comprehensive video Analysis\n",
        "In this code **'VideoAnalyzer'** class is defined. It is designed to perform various tasks on video files, including extracting audio, transcribing audio, analyzing sentiment, translating text, and extracting emotions. below is the brief overview of each method and its functionality:\n",
        "\n",
        "**Imports**\n",
        "\n",
        "*   **'moviepy.editor'**: For handling video files\n",
        "*   **'moviepy.editor'**: For handling video files\n",
        "*   **'TextBlob'**: For text processing, sentiment analysis, and translation.\n",
        "*   **'NRCLex'**: For extracting emotions from text.\n",
        "\n",
        "**Class Initialization**\n",
        "\n",
        "\n",
        "*   The **'VideoAnalyzer'** class initializes with an **'output_path'** to save processed files, defaulting to **'video_output'**\n",
        "\n",
        "**Methods:**\n",
        "\n",
        "\n",
        "1.   **'extract_audio(video_folder)':**\n",
        "\n",
        "   *   Extracts audio from the first **'.mp4'** video file in the specified folder.\n",
        "   *   Saves the audio as a **'.wav'** file.\n",
        "\n",
        "\n",
        "2.   **'transcribe_audio(audio_path, language='en-US')'**:\n",
        "\n",
        "   *   Converts audio from a **'.wav'** file to text using Google's Web Speech API.\n",
        "   *   Handles various exceptions and returns the transcribed text.\n",
        "\n",
        "\n",
        "3.   **'analyze_sentiment(text)'**:\n",
        "\n",
        "   *   Analyzes the sentiment of the text using TextBlob.\n",
        "   *   Returns polarity (positive/negative) and subjectivity scores of the text.\n",
        "\n",
        "\n",
        "4.   **'translate_text(text, from_lang='en', to_lang='es')'**:\n",
        "\n",
        "   *   Translates text from English to Spanish using TextBlob.\n",
        "   *   Handles errors and ensures the input is a string.\n",
        "\n",
        "\n",
        "5.   **'extract_emotions(text)'**:\n",
        "\n",
        "   *   Extracts emotional content from the given text using NRCLex.\n",
        "   *   Returns a dictionary with the frequencies of various emotions.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7gXmtpXOV9-9"
      },
      "outputs": [],
      "source": [
        "from moviepy.editor import VideoFileClip\n",
        "import speech_recognition as sr\n",
        "from textblob import TextBlob\n",
        "from nrclex import NRCLex\n",
        "\n",
        "class VideoAnalyzer:\n",
        "    def __init__(self, output_path='video_output'):\n",
        "        self.output_path = output_path\n",
        "\n",
        "    def extract_audio(self, video_folder):\n",
        "        try:\n",
        "            video_file = [f for f in os.listdir(video_folder) if f.endswith('.mp4')][0]\n",
        "            video_path = os.path.join(video_folder, video_file)\n",
        "            video = VideoFileClip(video_path)\n",
        "            audio_path = video_path.replace('.mp4', '.wav')\n",
        "            video.audio.write_audiofile(audio_path)\n",
        "            return audio_path\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to extract audio from {video_path}: {e}\")\n",
        "            return None\n",
        "\n",
        "    def transcribe_audio(self, audio_path, language='en-US'):\n",
        "        recognizer = sr.Recognizer()\n",
        "        try:\n",
        "            with sr.AudioFile(audio_path) as source:\n",
        "                audio = recognizer.record(source)\n",
        "            text = recognizer.recognize_google(audio, language=language)\n",
        "            return text\n",
        "        except sr.RequestError as e:\n",
        "            print(f\"Could not request results from Google Web Speech API; {e}\")\n",
        "        except sr.UnknownValueError:\n",
        "            print(f\"Google Web Speech API could not understand audio {audio_path}\")\n",
        "            return \"\"\n",
        "        except Exception as e:\n",
        "            print(f\"Error transcribing {audio_path}: {e}\")\n",
        "            return \"\"\n",
        "\n",
        "    def analyze_sentiment(self, text):\n",
        "        blob = TextBlob(text)\n",
        "        return blob.sentiment.polarity, blob.sentiment.subjectivity\n",
        "\n",
        "    def translate_text(self, text, from_lang='en', to_lang='es'):\n",
        "        print(f\"Type of text to be translated: {type(text)}\")  # Debugging output\n",
        "        if isinstance(text, str):\n",
        "            try:\n",
        "                blob = TextBlob(text)\n",
        "                translated = blob.translate(from_lang=from_lang, to=to_lang)\n",
        "                return str(translated)\n",
        "            except Exception as e:\n",
        "                print(f\"Translation error: {e}\")\n",
        "                return text\n",
        "        else:\n",
        "            print(\"Error: Input is not a string, cannot translate.\")\n",
        "            return text\n",
        "\n",
        "    def extract_emotions(self, text):\n",
        "        emotions = NRCLex(text)\n",
        "        return emotions.affect_frequencies\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbBH0ihZ_V7X"
      },
      "source": [
        "# 7. Extracting Audio from Video Files\n",
        " The **'extract_audio'** method extracts audio from video files and saves them as **.wav** files. The **'main_extract_audio'** function iterates through the downloaded video folders and extracts audio for each video."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ss4WLlFOWAef"
      },
      "outputs": [],
      "source": [
        "def main_extract_audio():\n",
        "    analyzer = VideoAnalyzer()\n",
        "    video_folders = [os.path.join('video_output', f) for f in os.listdir('video_output') if os.path.isdir(os.path.join('video_output', f))]\n",
        "    for video_folder in video_folders:\n",
        "        audio_path = analyzer.extract_audio(video_folder)\n",
        "        if audio_path:\n",
        "            print(f\"Extracted audio to {audio_path}\")\n",
        "        else:\n",
        "            print(f\"Skipping audio extraction for {video_folder}\")\n",
        "\n",
        "main_extract_audio()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72wSDDW8AhSV"
      },
      "source": [
        "# 8. Transcribing Audio to Text\n",
        "This code transcribes the audio extracted from the videos to text and saves the transcriptions as text files. The **'transcribe_audio'** method uses the Google Web Speech API to convert audio to text. The **'main_transcribe_audio'** function iterates through the audio files in the video folders and transcribes each audio file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0T9RqF6HWDBV"
      },
      "outputs": [],
      "source": [
        "def main_transcribe_audio():\n",
        "    analyzer = VideoAnalyzer()\n",
        "    video_folders = [os.path.join('video_output', f) for f in os.listdir('video_output') if os.path.isdir(os.path.join('video_output', f))]\n",
        "    for video_folder in video_folders:\n",
        "        audio_files = [f for f in os.listdir(video_folder) if f.endswith('.wav')]\n",
        "        if audio_files:\n",
        "            audio_path = os.path.join(video_folder, audio_files[0])\n",
        "            transcription = analyzer.transcribe_audio(audio_path)\n",
        "            transcription_path = audio_path.replace('.wav', '.txt')\n",
        "            with open(transcription_path, 'w', encoding='utf-8', errors='ignore') as file:\n",
        "                file.write(transcription)\n",
        "            print(f\"Transcription for {audio_path}: {transcription}\")\n",
        "        else:\n",
        "            print(f\"Audio file for {video_folder} does not exist.\")\n",
        "\n",
        "main_transcribe_audio()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6UDORasBSCP"
      },
      "source": [
        "# 9. Analyzing Sentiments\n",
        "This code analyzes the sentiment of the transcribed text, calculating the polarity and subjectivity of each video transcription. The **'analyze_sentiment'** method uses the TextBlob library to determine the sentiment. The **'main_analyze_sentiment'** function iterates through the transcription files in the video folders and analyzes the sentiment of each transcription."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qKf3smtCWE0_"
      },
      "outputs": [],
      "source": [
        "\n",
        "def main_analyze_sentiment():\n",
        "    analyzer = VideoAnalyzer()\n",
        "    video_folders = [os.path.join('video_output', f) for f in os.listdir('video_output') if os.path.isdir(os.path.join('video_output', f))]\n",
        "    for video_folder in video_folders:\n",
        "        transcription_files = [f for f in os.listdir(video_folder) if f.endswith('.txt') and not '_emotions.txt' in f and not '_translated.txt' in f]\n",
        "        if transcription_files:\n",
        "            transcription_path = os.path.join(video_folder, transcription_files[0])\n",
        "            with open(transcription_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
        "                transcription = file.read()\n",
        "            polarity, subjectivity = analyzer.analyze_sentiment(transcription)\n",
        "            print(f\"Video: {os.path.basename(video_folder)} - Polarity: {polarity}, Subjectivity: {subjectivity}\")\n",
        "        else:\n",
        "            print(f\"Transcription file for {video_folder} does not exist.\")\n",
        "\n",
        "main_analyze_sentiment()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8a92cD4B6KK"
      },
      "source": [
        "# 10. Translating Text\n",
        "It translates the transcribed text into Spanish using the TextBlob library. The **'translate_text'** method translates the text from English to Spanish. The **'main_translate_text'** function iterates through the transcription files in the video folders and translates each transcription."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2IQokHdTWGWC"
      },
      "outputs": [],
      "source": [
        "def main_translate_text():\n",
        "    analyzer = VideoAnalyzer()\n",
        "    video_folders = [os.path.join('video_output', f) for f in os.listdir('video_output') if os.path.isdir(os.path.join('video_output', f))]\n",
        "\n",
        "    for video_folder in video_folders:\n",
        "        transcription_files = [f for f in os.listdir(video_folder) if f.endswith('.txt') and not f.endswith('_translated.txt') and not f.endswith('_emotions.txt')]\n",
        "\n",
        "        if transcription_files:\n",
        "            transcription_path = os.path.join(video_folder, transcription_files[0])\n",
        "\n",
        "            with open(transcription_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
        "                transcription = file.read()\n",
        "\n",
        "            if isinstance(transcription, str):\n",
        "                translation = analyzer.translate_text(transcription, from_lang='en', to_lang='es')\n",
        "\n",
        "                translation_path = transcription_path.replace('.txt', '_translated.txt')\n",
        "                with open(translation_path, 'w', encoding='utf-8', errors='ignore') as file:\n",
        "                    file.write(translation)\n",
        "\n",
        "                print(f\"Translation for {transcription_path}: {translation}\")  # Display the full translation\n",
        "            else:\n",
        "                print(f\"Error: Transcription is not a string in file {transcription_path}\")\n",
        "        else:\n",
        "            print(f\"Transcription file for {video_folder} does not exist.\")\n",
        "\n",
        "main_translate_text()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQfHJksvCmMY"
      },
      "source": [
        "# 11. Extracting Emotions from Text\n",
        "This code extracts the emotions from the transcribed text using the NRCLex library. The **'extract_emotions'** method uses NRCLex to analyze the emotions in the text. The **'main_extract_emotions'** function iterates through the transcription files in the video folders and extracts emotions for each transcription."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbMYNqGCWIY2"
      },
      "outputs": [],
      "source": [
        "def main_extract_emotions():\n",
        "    analyzer = VideoAnalyzer()\n",
        "    video_folders = [os.path.join('video_output', f) for f in os.listdir('video_output') if os.path.isdir(os.path.join('video_output', f))]\n",
        "    for video_folder in video_folders:\n",
        "        transcription_files = [f for f in os.listdir(video_folder) if f.endswith('.txt') and not f.endswith('_translated.txt') and not f.endswith('_emotions.txt')]\n",
        "        if transcription_files:\n",
        "            transcription_path = os.path.join(video_folder, transcription_files[0])\n",
        "            with open(transcription_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
        "                transcription = file.read()\n",
        "            emotions = analyzer.extract_emotions(transcription)\n",
        "            emotions_path = transcription_path.replace('.txt', '_emotions.txt')\n",
        "            with open(emotions_path, 'w', encoding='utf-8', errors='ignore') as file:\n",
        "                file.write(str(emotions))\n",
        "            print(f\"Emotions for {transcription_path}: {emotions}\")\n",
        "        else:\n",
        "            print(f\"Transcription file for {video_folder} does not exist.\")\n",
        "\n",
        "main_extract_emotions()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxbfXSwYDLeW"
      },
      "source": [
        "# 12. Main Execution Flow\n",
        "This code defines the main function that manages the entire workflow from downloading videos to extracting emotions. It sequentially calls the functions defined in the previous cells to create video URLs, read URLs, download videos, extract audio, transcribe audio, analyze sentiment, translate text, and extract emotions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IpAYqEdAWJ-9"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    # Create video URLs\n",
        "    main_create_urls()\n",
        "\n",
        "    # Read URLs\n",
        "    main_read_urls()\n",
        "\n",
        "    # Download videos\n",
        "    main_download()\n",
        "\n",
        "    # Extract audio\n",
        "    main_extract_audio()\n",
        "\n",
        "    # Transcribe audio\n",
        "    main_transcribe_audio()\n",
        "\n",
        "    # Analyze sentiment\n",
        "    main_analyze_sentiment()\n",
        "\n",
        "    # Translate text\n",
        "    main_translate_text()\n",
        "\n",
        "    # Extract emotions\n",
        "    main_extract_emotions()\n",
        "\n",
        "main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PyMP2U-UEEJN"
      },
      "source": [
        "# 13. Comparing Audio Extraction Methods\n",
        "This code compares the performance of serial, threading, and multiprocessing methods for extracting audio from videos. The **'serial_extract_audio'** function extracts audio serially. The **'threading_extract_audio'** function uses threading to extract audio in parallel. The **'multiprocessing_extract_audio'** function uses multiprocessing for parallel extraction. The **'main_compare_audio_extraction'** function compares the execution times of these methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IdlPKOw9WLxi"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from multiprocessing import Pool\n",
        "\n",
        "def serial_extract_audio(videos):\n",
        "    start_time = time.time()\n",
        "    analyzer = VideoAnalyzer()\n",
        "    for video_folder in videos:\n",
        "        analyzer.extract_audio(video_folder)\n",
        "    end_time = time.time()\n",
        "    print(f\"Serial extract audio time: {end_time - start_time} seconds\")\n",
        "\n",
        "def threading_extract_audio(videos):\n",
        "    start_time = time.time()\n",
        "    analyzer = VideoAnalyzer()\n",
        "    with ThreadPoolExecutor(max_workers=5) as executor:\n",
        "        executor.map(analyzer.extract_audio, videos)\n",
        "    end_time = time.time()\n",
        "    print(f\"Threading extract audio time: {end_time - start_time} seconds\")\n",
        "\n",
        "def multiprocessing_extract_audio(videos):\n",
        "    start_time = time.time()\n",
        "    analyzer = VideoAnalyzer()\n",
        "    with Pool(processes=5) as pool:\n",
        "        pool.map(analyzer.extract_audio, videos)\n",
        "    end_time = time.time()\n",
        "    print(f\"Multiprocessing extract audio time: {end_time - start_time} seconds\")\n",
        "\n",
        "def main_compare_audio_extraction():\n",
        "    video_folders = [os.path.join('video_output', f) for f in os.listdir('video_output') if os.path.isdir(os.path.join('video_output', f))]\n",
        "\n",
        "    print(\"Starting serial extract audio...\")\n",
        "    serial_extract_audio(video_folders)\n",
        "\n",
        "    print(\"Starting threading extract audio...\")\n",
        "    threading_extract_audio(video_folders)\n",
        "\n",
        "    print(\"Starting multiprocessing extract audio...\")\n",
        "    multiprocessing_extract_audio(video_folders)\n",
        "\n",
        "main_compare_audio_extraction()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azfxooECE9Bm"
      },
      "source": [
        "# 14. Strategy for Each Solution\n",
        "The strategy for developing the solution involved the following steps.\n",
        "\n",
        "*   **Library Installation:** Installing necessary libraries for video downloading, audio extraction, transcription, sentiment analysis, translation, and emotion extraction.\n",
        "\n",
        "*   **Video URL Management:** Creating and reading video URLs from a text file.\n",
        "\n",
        "*   **Video Downloading:** The download task was implemented using both serial and parallel processing. In the parallel approach, threads and semaphores were used to control the number of simultaneous downloads to avoid YouTube blocks.\n",
        "\n",
        "*   **Logging:** Logging was implemented to record which video was downloaded by which process or thread. This was achieved using the logging module and a mutex to ensure thread-safe logging.\n",
        "\n",
        "*   **Audio Processing:** Extracting audio from downloaded videos, transcribing audio to text, and saving transcriptions.\n",
        "\n",
        "*   **Text Analysis:** Performing sentiment analysis, translating text to Spanish, and extracting emotions from the text. Each task was implemented in a separate function to maintain modularity.\n",
        "\n",
        "*   **Comparing Methods:** The performance of serial, threading, and multiprocessing methods for extracting audio was compared. Multiprocessing showed significant performance improvement over serial and threading methods."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIH_3UH_H6T2"
      },
      "source": [
        "# 15. Conclusion\n",
        "The project successfully demonstrated the development of a Python application for downloading and analyzing YouTube videos using various parallel processing techniques. By utilizing threads and multiprocessing, the overall execution time was significantly reduced compared to the serial approach. By comparing serial and parallel processing methods, significant performance improvements were observed, making it feasible to analyze large volumes of social media video content efficiently. This approach enables CineSense to provide valuable insights to businesses, enhancing their understanding of audience sentiments and emotions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFvVcHzvOSlK"
      },
      "source": [
        "# 16. Appendix\n",
        "**Use of Grammarly**\n",
        "\n",
        "To ensure the quality and clarity of this project report, I have used grammarly to review and refine the text. Grammarly helped to correct grammatical errors, improve sentence structure, and enhance overall readability."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
